name: Performance Benchmarks

on:
  push:
    branches:
      - main
      - develop
  pull_request:
    branches:
      - main
      - develop
  workflow_dispatch:
    inputs:
      benchmark_filter:
        description: 'Benchmark filter pattern (default: full suite)'
        required: false
        type: string
        default: '*'
      baseline_ref:
        description: 'Git ref to use as baseline (default: base branch or HEAD~1)'
        required: false
        type: string

concurrency:
  group: benchmarks-${{ github.ref }}
  cancel-in-progress: true

env:
  DOTNET_NOLOGO: true
  DOTNET_CLI_TELEMETRY_OPTOUT: true
  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: true

jobs:
  benchmark:
    name: Run Benchmarks
    runs-on: ubuntu-latest
    permissions:
      pull-requests: write
      contents: read

    steps:
      - name: Checkout PR branch
        uses: actions/checkout@v6
        with:
          fetch-depth: 0

      - name: Setup .NET
        uses: actions/setup-dotnet@v5
        with:
          dotnet-version: '10.0.x'
          dotnet-quality: 'preview'

      - name: Determine benchmark configuration
        id: config
        run: |
          # PRs run smoke tests only (fast), pushes to main/develop run full suite
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            echo "filter=*SmokeTest*" >> $GITHUB_OUTPUT
            echo "timeout=10" >> $GITHUB_OUTPUT
            echo "mode=smoke" >> $GITHUB_OUTPUT
          elif [ -n "${{ inputs.benchmark_filter }}" ]; then
            echo "filter=${{ inputs.benchmark_filter }}" >> $GITHUB_OUTPUT
            echo "timeout=60" >> $GITHUB_OUTPUT
            echo "mode=custom" >> $GITHUB_OUTPUT
          else
            echo "filter=*" >> $GITHUB_OUTPUT
            echo "timeout=60" >> $GITHUB_OUTPUT
            echo "mode=full" >> $GITHUB_OUTPUT
          fi

          # Determine baseline ref
          if [ -n "${{ inputs.baseline_ref }}" ]; then
            echo "baseline=${{ inputs.baseline_ref }}" >> $GITHUB_OUTPUT
          elif [ "${{ github.event_name }}" = "pull_request" ]; then
            echo "baseline=${{ github.event.pull_request.base.sha }}" >> $GITHUB_OUTPUT
          else
            echo "baseline=HEAD~1" >> $GITHUB_OUTPUT
          fi

      - name: Print configuration
        run: |
          echo "Benchmark mode: ${{ steps.config.outputs.mode }}"
          echo "Filter: ${{ steps.config.outputs.filter }}"
          echo "Baseline: ${{ steps.config.outputs.baseline }}"
          echo "Timeout: ${{ steps.config.outputs.timeout }} minutes"

      - name: Build PR version
        run: dotnet build benchmarks/KeenEyes.Benchmarks -c Release

      - name: Run current benchmarks
        working-directory: benchmarks/KeenEyes.Benchmarks
        run: |
          dotnet run -c Release --no-build -- \
            --filter "${{ steps.config.outputs.filter }}" \
            --exporters json \
            --artifacts ../artifacts/current \
            --job short
        timeout-minutes: ${{ fromJson(steps.config.outputs.timeout) }}

      - name: Checkout baseline
        run: git checkout ${{ steps.config.outputs.baseline }}

      - name: Build baseline version
        run: dotnet build benchmarks/KeenEyes.Benchmarks -c Release

      - name: Run baseline benchmarks
        working-directory: benchmarks/KeenEyes.Benchmarks
        run: |
          dotnet run -c Release --no-build -- \
            --filter "${{ steps.config.outputs.filter }}" \
            --exporters json \
            --artifacts ../artifacts/baseline \
            --job short
        timeout-minutes: ${{ fromJson(steps.config.outputs.timeout) }}

      - name: Checkout back for comparison tool
        run: git checkout ${{ github.sha }}

      - name: Compare benchmark results
        id: compare
        run: |
          dotnet run --project tools/BenchmarkCompare \
            -- \
            --baseline benchmarks/artifacts/baseline \
            --current benchmarks/artifacts/current \
            --threshold 5.0 \
            --output benchmarks/artifacts/comparison.md

          # Check if there are regressions
          if grep -q "REGRESSION" benchmarks/artifacts/comparison.md; then
            echo "has_regressions=true" >> $GITHUB_OUTPUT
          else
            echo "has_regressions=false" >> $GITHUB_OUTPUT
          fi

      - name: Upload benchmark artifacts
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results-${{ steps.config.outputs.mode }}
          path: benchmarks/artifacts/
          retention-days: 30

      - name: Post PR comment
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const comparison = fs.readFileSync('benchmarks/artifacts/comparison.md', 'utf8');

            // Find existing comment to update
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number
            });

            const marker = '<!-- benchmark-results -->';
            const existingComment = comments.find(c => c.body.includes(marker));

            const mode = '${{ steps.config.outputs.mode }}';
            const modeNote = mode === 'smoke'
              ? '\n\n> **Note:** This is a smoke test run. Full benchmarks run on merge to main/develop.'
              : '';

            const body = `${marker}\n## Performance Benchmark Results\n\n${comparison}${modeNote}`;

            if (existingComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: existingComment.id,
                body: body
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: body
              });
            }

      - name: Check for regressions
        if: steps.compare.outputs.has_regressions == 'true'
        run: |
          echo "::warning::Performance regressions detected! See the comparison report for details."
          # Uncomment to fail the build on regressions:
          # exit 1
